{
  "best_global_step": 2280,
  "best_metric": 1.6227099895477295,
  "best_model_checkpoint": "./wav2vec2-finetuned-moviesubs/checkpoint-2280",
  "epoch": 40.0,
  "eval_steps": 500,
  "global_step": 2280,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 32.273155212402344,
      "learning_rate": 9.979910714285715e-07,
      "loss": 3.9852,
      "step": 10
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 25.2960262298584,
      "learning_rate": 9.957589285714285e-07,
      "loss": 3.454,
      "step": 20
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 25.565420150756836,
      "learning_rate": 9.935267857142857e-07,
      "loss": 3.4443,
      "step": 30
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 19.907453536987305,
      "learning_rate": 9.91294642857143e-07,
      "loss": 3.2632,
      "step": 40
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 14.897856712341309,
      "learning_rate": 9.890625e-07,
      "loss": 3.1861,
      "step": 50
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.9106354713439941,
      "eval_runtime": 31.5034,
      "eval_samples_per_second": 3.206,
      "eval_steps_per_second": 0.222,
      "eval_wer": 0.6647096159949223,
      "step": 57
    },
    {
      "epoch": 1.0530973451327434,
      "grad_norm": 18.203088760375977,
      "learning_rate": 9.868303571428571e-07,
      "loss": 2.9797,
      "step": 60
    },
    {
      "epoch": 1.2300884955752212,
      "grad_norm": 13.211233139038086,
      "learning_rate": 9.845982142857141e-07,
      "loss": 3.0595,
      "step": 70
    },
    {
      "epoch": 1.407079646017699,
      "grad_norm": 16.728548049926758,
      "learning_rate": 9.823660714285713e-07,
      "loss": 2.9783,
      "step": 80
    },
    {
      "epoch": 1.584070796460177,
      "grad_norm": 40.675662994384766,
      "learning_rate": 9.801339285714285e-07,
      "loss": 2.9788,
      "step": 90
    },
    {
      "epoch": 1.7610619469026547,
      "grad_norm": 9.61489486694336,
      "learning_rate": 9.779017857142857e-07,
      "loss": 2.9327,
      "step": 100
    },
    {
      "epoch": 1.9380530973451329,
      "grad_norm": 14.8967866897583,
      "learning_rate": 9.756696428571427e-07,
      "loss": 2.9437,
      "step": 110
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.8781201839447021,
      "eval_runtime": 31.8868,
      "eval_samples_per_second": 3.167,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.6635988575055538,
      "step": 114
    },
    {
      "epoch": 2.106194690265487,
      "grad_norm": 7.645829200744629,
      "learning_rate": 9.734375e-07,
      "loss": 2.7761,
      "step": 120
    },
    {
      "epoch": 2.2831858407079646,
      "grad_norm": 12.269218444824219,
      "learning_rate": 9.712053571428572e-07,
      "loss": 2.8434,
      "step": 130
    },
    {
      "epoch": 2.4601769911504423,
      "grad_norm": 12.408475875854492,
      "learning_rate": 9.689732142857142e-07,
      "loss": 2.8703,
      "step": 140
    },
    {
      "epoch": 2.6371681415929205,
      "grad_norm": 13.155181884765625,
      "learning_rate": 9.667410714285714e-07,
      "loss": 2.8721,
      "step": 150
    },
    {
      "epoch": 2.814159292035398,
      "grad_norm": 9.49323844909668,
      "learning_rate": 9.645089285714286e-07,
      "loss": 2.7939,
      "step": 160
    },
    {
      "epoch": 2.991150442477876,
      "grad_norm": 6.1591081619262695,
      "learning_rate": 9.622767857142858e-07,
      "loss": 2.769,
      "step": 170
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.86204993724823,
      "eval_runtime": 32.5111,
      "eval_samples_per_second": 3.107,
      "eval_steps_per_second": 0.215,
      "eval_wer": 0.6610599809584259,
      "step": 171
    },
    {
      "epoch": 3.15929203539823,
      "grad_norm": 22.298433303833008,
      "learning_rate": 9.600446428571428e-07,
      "loss": 2.6256,
      "step": 180
    },
    {
      "epoch": 3.336283185840708,
      "grad_norm": 8.172438621520996,
      "learning_rate": 9.578125e-07,
      "loss": 2.7283,
      "step": 190
    },
    {
      "epoch": 3.5132743362831858,
      "grad_norm": 7.4302144050598145,
      "learning_rate": 9.555803571428572e-07,
      "loss": 2.6942,
      "step": 200
    },
    {
      "epoch": 3.6902654867256635,
      "grad_norm": 7.40423583984375,
      "learning_rate": 9.533482142857142e-07,
      "loss": 2.7452,
      "step": 210
    },
    {
      "epoch": 3.8672566371681416,
      "grad_norm": 17.12115478515625,
      "learning_rate": 9.511160714285714e-07,
      "loss": 2.7013,
      "step": 220
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.8346946239471436,
      "eval_runtime": 32.0468,
      "eval_samples_per_second": 3.152,
      "eval_steps_per_second": 0.218,
      "eval_wer": 0.6539193906696287,
      "step": 228
    },
    {
      "epoch": 4.035398230088496,
      "grad_norm": 4.233940124511719,
      "learning_rate": 9.488839285714285e-07,
      "loss": 2.6093,
      "step": 230
    },
    {
      "epoch": 4.212389380530974,
      "grad_norm": 8.719173431396484,
      "learning_rate": 9.466517857142857e-07,
      "loss": 2.6541,
      "step": 240
    },
    {
      "epoch": 4.389380530973451,
      "grad_norm": 6.983406066894531,
      "learning_rate": 9.444196428571428e-07,
      "loss": 2.7205,
      "step": 250
    },
    {
      "epoch": 4.566371681415929,
      "grad_norm": 6.431542873382568,
      "learning_rate": 9.421874999999999e-07,
      "loss": 2.6511,
      "step": 260
    },
    {
      "epoch": 4.743362831858407,
      "grad_norm": 5.8683695793151855,
      "learning_rate": 9.399553571428571e-07,
      "loss": 2.6719,
      "step": 270
    },
    {
      "epoch": 4.920353982300885,
      "grad_norm": 8.135319709777832,
      "learning_rate": 9.377232142857142e-07,
      "loss": 2.689,
      "step": 280
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.8100104331970215,
      "eval_runtime": 32.1325,
      "eval_samples_per_second": 3.143,
      "eval_steps_per_second": 0.218,
      "eval_wer": 0.6423357664233577,
      "step": 285
    },
    {
      "epoch": 5.088495575221239,
      "grad_norm": 5.609757423400879,
      "learning_rate": 9.354910714285714e-07,
      "loss": 2.5496,
      "step": 290
    },
    {
      "epoch": 5.265486725663717,
      "grad_norm": 7.567227840423584,
      "learning_rate": 9.332589285714286e-07,
      "loss": 2.5948,
      "step": 300
    },
    {
      "epoch": 5.442477876106195,
      "grad_norm": 6.290599346160889,
      "learning_rate": 9.310267857142858e-07,
      "loss": 2.6478,
      "step": 310
    },
    {
      "epoch": 5.619469026548672,
      "grad_norm": 4.827550411224365,
      "learning_rate": 9.287946428571429e-07,
      "loss": 2.6119,
      "step": 320
    },
    {
      "epoch": 5.79646017699115,
      "grad_norm": 7.312129974365234,
      "learning_rate": 9.265624999999999e-07,
      "loss": 2.5796,
      "step": 330
    },
    {
      "epoch": 5.9734513274336285,
      "grad_norm": 6.142087936401367,
      "learning_rate": 9.243303571428571e-07,
      "loss": 2.6416,
      "step": 340
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.7905606031417847,
      "eval_runtime": 32.3594,
      "eval_samples_per_second": 3.121,
      "eval_steps_per_second": 0.216,
      "eval_wer": 0.6396382100920343,
      "step": 342
    },
    {
      "epoch": 6.1415929203539825,
      "grad_norm": 5.940148830413818,
      "learning_rate": 9.220982142857142e-07,
      "loss": 2.4645,
      "step": 350
    },
    {
      "epoch": 6.31858407079646,
      "grad_norm": 20.02094841003418,
      "learning_rate": 9.198660714285714e-07,
      "loss": 2.6321,
      "step": 360
    },
    {
      "epoch": 6.495575221238938,
      "grad_norm": 9.300488471984863,
      "learning_rate": 9.176339285714285e-07,
      "loss": 2.6196,
      "step": 370
    },
    {
      "epoch": 6.672566371681416,
      "grad_norm": 9.002281188964844,
      "learning_rate": 9.154017857142857e-07,
      "loss": 2.6,
      "step": 380
    },
    {
      "epoch": 6.849557522123893,
      "grad_norm": 9.0607328414917,
      "learning_rate": 9.131696428571428e-07,
      "loss": 2.6387,
      "step": 390
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.773966908454895,
      "eval_runtime": 31.846,
      "eval_samples_per_second": 3.172,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.63344969850841,
      "step": 399
    },
    {
      "epoch": 7.017699115044247,
      "grad_norm": 5.625375747680664,
      "learning_rate": 9.109374999999999e-07,
      "loss": 2.4661,
      "step": 400
    },
    {
      "epoch": 7.1946902654867255,
      "grad_norm": 4.716611862182617,
      "learning_rate": 9.087053571428571e-07,
      "loss": 2.6129,
      "step": 410
    },
    {
      "epoch": 7.371681415929204,
      "grad_norm": 8.723017692565918,
      "learning_rate": 9.064732142857142e-07,
      "loss": 2.5825,
      "step": 420
    },
    {
      "epoch": 7.548672566371682,
      "grad_norm": 6.358444690704346,
      "learning_rate": 9.042410714285714e-07,
      "loss": 2.6062,
      "step": 430
    },
    {
      "epoch": 7.725663716814159,
      "grad_norm": 9.772793769836426,
      "learning_rate": 9.020089285714285e-07,
      "loss": 2.5494,
      "step": 440
    },
    {
      "epoch": 7.902654867256637,
      "grad_norm": 5.023003101348877,
      "learning_rate": 8.997767857142857e-07,
      "loss": 2.5837,
      "step": 450
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.7655328512191772,
      "eval_runtime": 31.9231,
      "eval_samples_per_second": 3.164,
      "eval_steps_per_second": 0.219,
      "eval_wer": 0.6301174230403047,
      "step": 456
    },
    {
      "epoch": 8.070796460176991,
      "grad_norm": 4.801879405975342,
      "learning_rate": 8.975446428571428e-07,
      "loss": 2.4598,
      "step": 460
    },
    {
      "epoch": 8.247787610619469,
      "grad_norm": 6.7101826667785645,
      "learning_rate": 8.953125e-07,
      "loss": 2.5708,
      "step": 470
    },
    {
      "epoch": 8.424778761061948,
      "grad_norm": 5.379832744598389,
      "learning_rate": 8.930803571428572e-07,
      "loss": 2.5175,
      "step": 480
    },
    {
      "epoch": 8.601769911504425,
      "grad_norm": 3.977764368057251,
      "learning_rate": 8.908482142857143e-07,
      "loss": 2.5564,
      "step": 490
    },
    {
      "epoch": 8.778761061946902,
      "grad_norm": 6.1761088371276855,
      "learning_rate": 8.886160714285715e-07,
      "loss": 2.6149,
      "step": 500
    },
    {
      "epoch": 8.955752212389381,
      "grad_norm": 5.3185625076293945,
      "learning_rate": 8.863839285714285e-07,
      "loss": 2.6314,
      "step": 510
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.751833438873291,
      "eval_runtime": 32.0648,
      "eval_samples_per_second": 3.15,
      "eval_steps_per_second": 0.218,
      "eval_wer": 0.6256743890828308,
      "step": 513
    },
    {
      "epoch": 9.123893805309734,
      "grad_norm": 6.762805461883545,
      "learning_rate": 8.841517857142857e-07,
      "loss": 2.4217,
      "step": 520
    },
    {
      "epoch": 9.300884955752213,
      "grad_norm": 10.197325706481934,
      "learning_rate": 8.819196428571428e-07,
      "loss": 2.5777,
      "step": 530
    },
    {
      "epoch": 9.47787610619469,
      "grad_norm": 4.4518256187438965,
      "learning_rate": 8.796874999999999e-07,
      "loss": 2.5943,
      "step": 540
    },
    {
      "epoch": 9.654867256637168,
      "grad_norm": 7.3009796142578125,
      "learning_rate": 8.774553571428571e-07,
      "loss": 2.6172,
      "step": 550
    },
    {
      "epoch": 9.831858407079647,
      "grad_norm": 5.525852680206299,
      "learning_rate": 8.752232142857142e-07,
      "loss": 2.5414,
      "step": 560
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.044587135314941,
      "learning_rate": 8.729910714285714e-07,
      "loss": 2.4357,
      "step": 570
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.7341439723968506,
      "eval_runtime": 32.5202,
      "eval_samples_per_second": 3.106,
      "eval_steps_per_second": 0.215,
      "eval_wer": 0.6202792764201841,
      "step": 570
    },
    {
      "epoch": 10.176991150442477,
      "grad_norm": 5.33974027633667,
      "learning_rate": 8.707589285714285e-07,
      "loss": 2.5168,
      "step": 580
    },
    {
      "epoch": 10.353982300884956,
      "grad_norm": 5.216450214385986,
      "learning_rate": 8.685267857142857e-07,
      "loss": 2.5811,
      "step": 590
    },
    {
      "epoch": 10.530973451327434,
      "grad_norm": 6.002182483673096,
      "learning_rate": 8.662946428571428e-07,
      "loss": 2.5396,
      "step": 600
    },
    {
      "epoch": 10.70796460176991,
      "grad_norm": 6.24336576461792,
      "learning_rate": 8.640624999999999e-07,
      "loss": 2.5431,
      "step": 610
    },
    {
      "epoch": 10.88495575221239,
      "grad_norm": 4.8047990798950195,
      "learning_rate": 8.618303571428571e-07,
      "loss": 2.527,
      "step": 620
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.7235356569290161,
      "eval_runtime": 31.7242,
      "eval_samples_per_second": 3.184,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.6188511583624247,
      "step": 627
    },
    {
      "epoch": 11.053097345132743,
      "grad_norm": 5.561617851257324,
      "learning_rate": 8.595982142857142e-07,
      "loss": 2.4327,
      "step": 630
    },
    {
      "epoch": 11.230088495575222,
      "grad_norm": 4.551326274871826,
      "learning_rate": 8.573660714285715e-07,
      "loss": 2.5456,
      "step": 640
    },
    {
      "epoch": 11.4070796460177,
      "grad_norm": 3.739260673522949,
      "learning_rate": 8.551339285714286e-07,
      "loss": 2.4961,
      "step": 650
    },
    {
      "epoch": 11.584070796460177,
      "grad_norm": 7.691128730773926,
      "learning_rate": 8.529017857142858e-07,
      "loss": 2.6082,
      "step": 660
    },
    {
      "epoch": 11.761061946902656,
      "grad_norm": 5.760534763336182,
      "learning_rate": 8.506696428571429e-07,
      "loss": 2.4372,
      "step": 670
    },
    {
      "epoch": 11.938053097345133,
      "grad_norm": 5.692521572113037,
      "learning_rate": 8.484374999999999e-07,
      "loss": 2.5552,
      "step": 680
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.7216686010360718,
      "eval_runtime": 32.0031,
      "eval_samples_per_second": 3.156,
      "eval_steps_per_second": 0.219,
      "eval_wer": 0.6129800063471914,
      "step": 684
    },
    {
      "epoch": 12.106194690265486,
      "grad_norm": 5.204312801361084,
      "learning_rate": 8.462053571428571e-07,
      "loss": 2.4409,
      "step": 690
    },
    {
      "epoch": 12.283185840707965,
      "grad_norm": 7.286984443664551,
      "learning_rate": 8.439732142857142e-07,
      "loss": 2.5036,
      "step": 700
    },
    {
      "epoch": 12.460176991150442,
      "grad_norm": 5.015439033508301,
      "learning_rate": 8.417410714285714e-07,
      "loss": 2.5225,
      "step": 710
    },
    {
      "epoch": 12.63716814159292,
      "grad_norm": 4.082257270812988,
      "learning_rate": 8.395089285714285e-07,
      "loss": 2.5429,
      "step": 720
    },
    {
      "epoch": 12.814159292035399,
      "grad_norm": 7.796614170074463,
      "learning_rate": 8.372767857142857e-07,
      "loss": 2.5224,
      "step": 730
    },
    {
      "epoch": 12.991150442477876,
      "grad_norm": 5.792112350463867,
      "learning_rate": 8.350446428571428e-07,
      "loss": 2.5226,
      "step": 740
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.7155264616012573,
      "eval_runtime": 32.108,
      "eval_samples_per_second": 3.146,
      "eval_steps_per_second": 0.218,
      "eval_wer": 0.6121866074262139,
      "step": 741
    },
    {
      "epoch": 13.15929203539823,
      "grad_norm": 3.638488531112671,
      "learning_rate": 8.328124999999999e-07,
      "loss": 2.349,
      "step": 750
    },
    {
      "epoch": 13.336283185840708,
      "grad_norm": 3.6329588890075684,
      "learning_rate": 8.305803571428571e-07,
      "loss": 2.555,
      "step": 760
    },
    {
      "epoch": 13.513274336283185,
      "grad_norm": 4.908502578735352,
      "learning_rate": 8.283482142857142e-07,
      "loss": 2.5529,
      "step": 770
    },
    {
      "epoch": 13.690265486725664,
      "grad_norm": 6.11234712600708,
      "learning_rate": 8.261160714285714e-07,
      "loss": 2.5263,
      "step": 780
    },
    {
      "epoch": 13.867256637168142,
      "grad_norm": 11.989575386047363,
      "learning_rate": 8.238839285714285e-07,
      "loss": 2.486,
      "step": 790
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.704003930091858,
      "eval_runtime": 32.1319,
      "eval_samples_per_second": 3.143,
      "eval_steps_per_second": 0.218,
      "eval_wer": 0.610599809584259,
      "step": 798
    },
    {
      "epoch": 14.035398230088495,
      "grad_norm": 4.772345542907715,
      "learning_rate": 8.216517857142858e-07,
      "loss": 2.396,
      "step": 800
    },
    {
      "epoch": 14.212389380530974,
      "grad_norm": 6.832829475402832,
      "learning_rate": 8.194196428571429e-07,
      "loss": 2.4944,
      "step": 810
    },
    {
      "epoch": 14.389380530973451,
      "grad_norm": 4.948245048522949,
      "learning_rate": 8.171875e-07,
      "loss": 2.5277,
      "step": 820
    },
    {
      "epoch": 14.56637168141593,
      "grad_norm": 5.123713493347168,
      "learning_rate": 8.149553571428572e-07,
      "loss": 2.5261,
      "step": 830
    },
    {
      "epoch": 14.743362831858407,
      "grad_norm": 6.984799385070801,
      "learning_rate": 8.127232142857143e-07,
      "loss": 2.5111,
      "step": 840
    },
    {
      "epoch": 14.920353982300885,
      "grad_norm": 5.209042549133301,
      "learning_rate": 8.104910714285714e-07,
      "loss": 2.5354,
      "step": 850
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.7075351476669312,
      "eval_runtime": 32.2422,
      "eval_samples_per_second": 3.133,
      "eval_steps_per_second": 0.217,
      "eval_wer": 0.609965090447477,
      "step": 855
    },
    {
      "epoch": 15.08849557522124,
      "grad_norm": 13.336227416992188,
      "learning_rate": 8.082589285714285e-07,
      "loss": 2.3858,
      "step": 860
    },
    {
      "epoch": 15.265486725663717,
      "grad_norm": 5.563747882843018,
      "learning_rate": 8.060267857142857e-07,
      "loss": 2.5622,
      "step": 870
    },
    {
      "epoch": 15.442477876106194,
      "grad_norm": 5.749018669128418,
      "learning_rate": 8.037946428571428e-07,
      "loss": 2.5099,
      "step": 880
    },
    {
      "epoch": 15.619469026548673,
      "grad_norm": 3.953683853149414,
      "learning_rate": 8.015624999999999e-07,
      "loss": 2.5193,
      "step": 890
    },
    {
      "epoch": 15.79646017699115,
      "grad_norm": 7.039099216461182,
      "learning_rate": 7.993303571428571e-07,
      "loss": 2.5468,
      "step": 900
    },
    {
      "epoch": 15.973451327433628,
      "grad_norm": 4.869818687438965,
      "learning_rate": 7.970982142857142e-07,
      "loss": 2.4654,
      "step": 910
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.6996263265609741,
      "eval_runtime": 32.2678,
      "eval_samples_per_second": 3.13,
      "eval_steps_per_second": 0.217,
      "eval_wer": 0.6094890510948905,
      "step": 912
    },
    {
      "epoch": 16.141592920353983,
      "grad_norm": 4.901120185852051,
      "learning_rate": 7.948660714285714e-07,
      "loss": 2.3871,
      "step": 920
    },
    {
      "epoch": 16.31858407079646,
      "grad_norm": 4.46606969833374,
      "learning_rate": 7.926339285714285e-07,
      "loss": 2.5388,
      "step": 930
    },
    {
      "epoch": 16.495575221238937,
      "grad_norm": 5.4599995613098145,
      "learning_rate": 7.904017857142857e-07,
      "loss": 2.5175,
      "step": 940
    },
    {
      "epoch": 16.672566371681416,
      "grad_norm": 4.517430782318115,
      "learning_rate": 7.881696428571428e-07,
      "loss": 2.4882,
      "step": 950
    },
    {
      "epoch": 16.849557522123895,
      "grad_norm": 4.190997123718262,
      "learning_rate": 7.859374999999999e-07,
      "loss": 2.5291,
      "step": 960
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.694068193435669,
      "eval_runtime": 31.1923,
      "eval_samples_per_second": 3.238,
      "eval_steps_per_second": 0.224,
      "eval_wer": 0.609013011742304,
      "step": 969
    },
    {
      "epoch": 17.01769911504425,
      "grad_norm": 5.083795547485352,
      "learning_rate": 7.837053571428571e-07,
      "loss": 2.3993,
      "step": 970
    },
    {
      "epoch": 17.194690265486727,
      "grad_norm": 5.259410381317139,
      "learning_rate": 7.814732142857143e-07,
      "loss": 2.5572,
      "step": 980
    },
    {
      "epoch": 17.371681415929203,
      "grad_norm": 5.223203182220459,
      "learning_rate": 7.792410714285715e-07,
      "loss": 2.5176,
      "step": 990
    },
    {
      "epoch": 17.548672566371682,
      "grad_norm": 6.770071506500244,
      "learning_rate": 7.770089285714286e-07,
      "loss": 2.4885,
      "step": 1000
    },
    {
      "epoch": 17.72566371681416,
      "grad_norm": 4.182987689971924,
      "learning_rate": 7.747767857142858e-07,
      "loss": 2.4938,
      "step": 1010
    },
    {
      "epoch": 17.902654867256636,
      "grad_norm": 5.465175628662109,
      "learning_rate": 7.725446428571428e-07,
      "loss": 2.5095,
      "step": 1020
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.687293529510498,
      "eval_runtime": 32.223,
      "eval_samples_per_second": 3.134,
      "eval_steps_per_second": 0.217,
      "eval_wer": 0.6063154554109806,
      "step": 1026
    },
    {
      "epoch": 18.07079646017699,
      "grad_norm": 3.1458330154418945,
      "learning_rate": 7.703124999999999e-07,
      "loss": 2.3665,
      "step": 1030
    },
    {
      "epoch": 18.24778761061947,
      "grad_norm": 4.160404205322266,
      "learning_rate": 7.680803571428571e-07,
      "loss": 2.4623,
      "step": 1040
    },
    {
      "epoch": 18.424778761061948,
      "grad_norm": 6.271220684051514,
      "learning_rate": 7.658482142857142e-07,
      "loss": 2.4469,
      "step": 1050
    },
    {
      "epoch": 18.601769911504427,
      "grad_norm": 6.430055141448975,
      "learning_rate": 7.636160714285714e-07,
      "loss": 2.5133,
      "step": 1060
    },
    {
      "epoch": 18.778761061946902,
      "grad_norm": 6.038161754608154,
      "learning_rate": 7.613839285714285e-07,
      "loss": 2.5295,
      "step": 1070
    },
    {
      "epoch": 18.95575221238938,
      "grad_norm": 29.561237335205078,
      "learning_rate": 7.591517857142857e-07,
      "loss": 2.5165,
      "step": 1080
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.687432050704956,
      "eval_runtime": 31.809,
      "eval_samples_per_second": 3.175,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.608060933037131,
      "step": 1083
    },
    {
      "epoch": 19.123893805309734,
      "grad_norm": 5.058831691741943,
      "learning_rate": 7.569196428571428e-07,
      "loss": 2.365,
      "step": 1090
    },
    {
      "epoch": 19.300884955752213,
      "grad_norm": 6.614853858947754,
      "learning_rate": 7.546874999999999e-07,
      "loss": 2.5139,
      "step": 1100
    },
    {
      "epoch": 19.47787610619469,
      "grad_norm": 4.858394622802734,
      "learning_rate": 7.524553571428571e-07,
      "loss": 2.5006,
      "step": 1110
    },
    {
      "epoch": 19.654867256637168,
      "grad_norm": 4.037860870361328,
      "learning_rate": 7.502232142857142e-07,
      "loss": 2.4835,
      "step": 1120
    },
    {
      "epoch": 19.831858407079647,
      "grad_norm": 6.515511512756348,
      "learning_rate": 7.479910714285714e-07,
      "loss": 2.5774,
      "step": 1130
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.0908710956573486,
      "learning_rate": 7.457589285714285e-07,
      "loss": 2.4004,
      "step": 1140
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.6768407821655273,
      "eval_runtime": 31.6035,
      "eval_samples_per_second": 3.196,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.6058394160583942,
      "step": 1140
    },
    {
      "epoch": 20.17699115044248,
      "grad_norm": 4.5139265060424805,
      "learning_rate": 7.435267857142858e-07,
      "loss": 2.4679,
      "step": 1150
    },
    {
      "epoch": 20.353982300884955,
      "grad_norm": 4.425999164581299,
      "learning_rate": 7.412946428571429e-07,
      "loss": 2.521,
      "step": 1160
    },
    {
      "epoch": 20.530973451327434,
      "grad_norm": 3.916694164276123,
      "learning_rate": 7.390625e-07,
      "loss": 2.4571,
      "step": 1170
    },
    {
      "epoch": 20.707964601769913,
      "grad_norm": 5.342838287353516,
      "learning_rate": 7.368303571428572e-07,
      "loss": 2.4952,
      "step": 1180
    },
    {
      "epoch": 20.884955752212388,
      "grad_norm": 3.9177117347717285,
      "learning_rate": 7.345982142857142e-07,
      "loss": 2.5175,
      "step": 1190
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.6810221672058105,
      "eval_runtime": 31.4744,
      "eval_samples_per_second": 3.209,
      "eval_steps_per_second": 0.222,
      "eval_wer": 0.6052046969216122,
      "step": 1197
    },
    {
      "epoch": 21.053097345132745,
      "grad_norm": 4.519617557525635,
      "learning_rate": 7.323660714285714e-07,
      "loss": 2.4033,
      "step": 1200
    },
    {
      "epoch": 21.23008849557522,
      "grad_norm": 8.516768455505371,
      "learning_rate": 7.301339285714285e-07,
      "loss": 2.5245,
      "step": 1210
    },
    {
      "epoch": 21.4070796460177,
      "grad_norm": 6.30573844909668,
      "learning_rate": 7.279017857142857e-07,
      "loss": 2.5051,
      "step": 1220
    },
    {
      "epoch": 21.58407079646018,
      "grad_norm": 4.626556396484375,
      "learning_rate": 7.256696428571428e-07,
      "loss": 2.5123,
      "step": 1230
    },
    {
      "epoch": 21.761061946902654,
      "grad_norm": 4.712105751037598,
      "learning_rate": 7.234374999999999e-07,
      "loss": 2.4511,
      "step": 1240
    },
    {
      "epoch": 21.938053097345133,
      "grad_norm": 6.61537504196167,
      "learning_rate": 7.212053571428571e-07,
      "loss": 2.4871,
      "step": 1250
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.6726213693618774,
      "eval_runtime": 31.7781,
      "eval_samples_per_second": 3.178,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.6063154554109806,
      "step": 1254
    },
    {
      "epoch": 22.106194690265486,
      "grad_norm": 5.287755012512207,
      "learning_rate": 7.189732142857142e-07,
      "loss": 2.3932,
      "step": 1260
    },
    {
      "epoch": 22.283185840707965,
      "grad_norm": 6.709117889404297,
      "learning_rate": 7.167410714285714e-07,
      "loss": 2.501,
      "step": 1270
    },
    {
      "epoch": 22.460176991150444,
      "grad_norm": 3.2702677249908447,
      "learning_rate": 7.145089285714285e-07,
      "loss": 2.4487,
      "step": 1280
    },
    {
      "epoch": 22.63716814159292,
      "grad_norm": 4.468032360076904,
      "learning_rate": 7.122767857142857e-07,
      "loss": 2.5112,
      "step": 1290
    },
    {
      "epoch": 22.8141592920354,
      "grad_norm": 4.317507266998291,
      "learning_rate": 7.100446428571428e-07,
      "loss": 2.4864,
      "step": 1300
    },
    {
      "epoch": 22.991150442477878,
      "grad_norm": 10.775513648986816,
      "learning_rate": 7.078124999999999e-07,
      "loss": 2.4872,
      "step": 1310
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.6731476783752441,
      "eval_runtime": 31.9608,
      "eval_samples_per_second": 3.16,
      "eval_steps_per_second": 0.219,
      "eval_wer": 0.6050460171374167,
      "step": 1311
    },
    {
      "epoch": 23.15929203539823,
      "grad_norm": 4.441542625427246,
      "learning_rate": 7.055803571428572e-07,
      "loss": 2.3747,
      "step": 1320
    },
    {
      "epoch": 23.336283185840706,
      "grad_norm": 11.704276084899902,
      "learning_rate": 7.033482142857143e-07,
      "loss": 2.4465,
      "step": 1330
    },
    {
      "epoch": 23.513274336283185,
      "grad_norm": 4.561692237854004,
      "learning_rate": 7.011160714285715e-07,
      "loss": 2.4859,
      "step": 1340
    },
    {
      "epoch": 23.690265486725664,
      "grad_norm": 3.8219308853149414,
      "learning_rate": 6.988839285714286e-07,
      "loss": 2.4763,
      "step": 1350
    },
    {
      "epoch": 23.86725663716814,
      "grad_norm": 10.476439476013184,
      "learning_rate": 6.966517857142858e-07,
      "loss": 2.4238,
      "step": 1360
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.671533226966858,
      "eval_runtime": 31.1251,
      "eval_samples_per_second": 3.245,
      "eval_steps_per_second": 0.225,
      "eval_wer": 0.6064741351951761,
      "step": 1368
    },
    {
      "epoch": 24.035398230088497,
      "grad_norm": 5.874749183654785,
      "learning_rate": 6.944196428571428e-07,
      "loss": 2.4174,
      "step": 1370
    },
    {
      "epoch": 24.212389380530972,
      "grad_norm": 3.652952194213867,
      "learning_rate": 6.921874999999999e-07,
      "loss": 2.5011,
      "step": 1380
    },
    {
      "epoch": 24.38938053097345,
      "grad_norm": 4.7913641929626465,
      "learning_rate": 6.899553571428571e-07,
      "loss": 2.4819,
      "step": 1390
    },
    {
      "epoch": 24.56637168141593,
      "grad_norm": 4.02064847946167,
      "learning_rate": 6.877232142857142e-07,
      "loss": 2.4869,
      "step": 1400
    },
    {
      "epoch": 24.743362831858406,
      "grad_norm": 3.8022496700286865,
      "learning_rate": 6.854910714285714e-07,
      "loss": 2.532,
      "step": 1410
    },
    {
      "epoch": 24.920353982300885,
      "grad_norm": 4.227569580078125,
      "learning_rate": 6.832589285714285e-07,
      "loss": 2.4834,
      "step": 1420
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.6554287672042847,
      "eval_runtime": 31.3363,
      "eval_samples_per_second": 3.223,
      "eval_steps_per_second": 0.223,
      "eval_wer": 0.6020311012377023,
      "step": 1425
    },
    {
      "epoch": 25.088495575221238,
      "grad_norm": 7.863256931304932,
      "learning_rate": 6.810267857142857e-07,
      "loss": 2.3656,
      "step": 1430
    },
    {
      "epoch": 25.265486725663717,
      "grad_norm": 4.2985758781433105,
      "learning_rate": 6.787946428571428e-07,
      "loss": 2.4707,
      "step": 1440
    },
    {
      "epoch": 25.442477876106196,
      "grad_norm": 4.824246406555176,
      "learning_rate": 6.765624999999999e-07,
      "loss": 2.4654,
      "step": 1450
    },
    {
      "epoch": 25.61946902654867,
      "grad_norm": 5.438723564147949,
      "learning_rate": 6.743303571428571e-07,
      "loss": 2.4811,
      "step": 1460
    },
    {
      "epoch": 25.79646017699115,
      "grad_norm": 6.636132717132568,
      "learning_rate": 6.720982142857142e-07,
      "loss": 2.4444,
      "step": 1470
    },
    {
      "epoch": 25.97345132743363,
      "grad_norm": 5.7510576248168945,
      "learning_rate": 6.698660714285715e-07,
      "loss": 2.5222,
      "step": 1480
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.6666289567947388,
      "eval_runtime": 31.5927,
      "eval_samples_per_second": 3.197,
      "eval_steps_per_second": 0.222,
      "eval_wer": 0.6028245001586798,
      "step": 1482
    },
    {
      "epoch": 26.141592920353983,
      "grad_norm": 11.450417518615723,
      "learning_rate": 6.676339285714286e-07,
      "loss": 2.3672,
      "step": 1490
    },
    {
      "epoch": 26.31858407079646,
      "grad_norm": 5.0147624015808105,
      "learning_rate": 6.654017857142858e-07,
      "loss": 2.4414,
      "step": 1500
    },
    {
      "epoch": 26.495575221238937,
      "grad_norm": 12.254995346069336,
      "learning_rate": 6.631696428571429e-07,
      "loss": 2.4832,
      "step": 1510
    },
    {
      "epoch": 26.672566371681416,
      "grad_norm": 5.8088884353637695,
      "learning_rate": 6.609375e-07,
      "loss": 2.4967,
      "step": 1520
    },
    {
      "epoch": 26.849557522123895,
      "grad_norm": 4.917398929595947,
      "learning_rate": 6.587053571428572e-07,
      "loss": 2.4429,
      "step": 1530
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.6606475114822388,
      "eval_runtime": 31.6284,
      "eval_samples_per_second": 3.193,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.6017137416693114,
      "step": 1539
    },
    {
      "epoch": 27.01769911504425,
      "grad_norm": 4.3823747634887695,
      "learning_rate": 6.564732142857142e-07,
      "loss": 2.3447,
      "step": 1540
    },
    {
      "epoch": 27.194690265486727,
      "grad_norm": 4.662391662597656,
      "learning_rate": 6.542410714285714e-07,
      "loss": 2.5141,
      "step": 1550
    },
    {
      "epoch": 27.371681415929203,
      "grad_norm": 5.108248233795166,
      "learning_rate": 6.520089285714285e-07,
      "loss": 2.4999,
      "step": 1560
    },
    {
      "epoch": 27.548672566371682,
      "grad_norm": 10.179230690002441,
      "learning_rate": 6.497767857142857e-07,
      "loss": 2.5343,
      "step": 1570
    },
    {
      "epoch": 27.72566371681416,
      "grad_norm": 6.339071273803711,
      "learning_rate": 6.475446428571428e-07,
      "loss": 2.4591,
      "step": 1580
    },
    {
      "epoch": 27.902654867256636,
      "grad_norm": 5.183659553527832,
      "learning_rate": 6.453124999999999e-07,
      "loss": 2.4892,
      "step": 1590
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.663589358329773,
      "eval_runtime": 31.2244,
      "eval_samples_per_second": 3.235,
      "eval_steps_per_second": 0.224,
      "eval_wer": 0.6015550618851159,
      "step": 1596
    },
    {
      "epoch": 28.07079646017699,
      "grad_norm": 4.7802815437316895,
      "learning_rate": 6.430803571428571e-07,
      "loss": 2.3544,
      "step": 1600
    },
    {
      "epoch": 28.24778761061947,
      "grad_norm": 4.561765193939209,
      "learning_rate": 6.408482142857142e-07,
      "loss": 2.4684,
      "step": 1610
    },
    {
      "epoch": 28.424778761061948,
      "grad_norm": 3.899091958999634,
      "learning_rate": 6.386160714285714e-07,
      "loss": 2.5112,
      "step": 1620
    },
    {
      "epoch": 28.601769911504427,
      "grad_norm": 4.7281365394592285,
      "learning_rate": 6.363839285714285e-07,
      "loss": 2.4377,
      "step": 1630
    },
    {
      "epoch": 28.778761061946902,
      "grad_norm": 13.269488334655762,
      "learning_rate": 6.341517857142857e-07,
      "loss": 2.4721,
      "step": 1640
    },
    {
      "epoch": 28.95575221238938,
      "grad_norm": 16.205730438232422,
      "learning_rate": 6.319196428571428e-07,
      "loss": 2.4959,
      "step": 1650
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.6563303470611572,
      "eval_runtime": 31.4749,
      "eval_samples_per_second": 3.209,
      "eval_steps_per_second": 0.222,
      "eval_wer": 0.5972707077118375,
      "step": 1653
    },
    {
      "epoch": 29.123893805309734,
      "grad_norm": 5.991495609283447,
      "learning_rate": 6.296875e-07,
      "loss": 2.358,
      "step": 1660
    },
    {
      "epoch": 29.300884955752213,
      "grad_norm": 4.830198287963867,
      "learning_rate": 6.274553571428572e-07,
      "loss": 2.4432,
      "step": 1670
    },
    {
      "epoch": 29.47787610619469,
      "grad_norm": 3.8429112434387207,
      "learning_rate": 6.252232142857143e-07,
      "loss": 2.5389,
      "step": 1680
    },
    {
      "epoch": 29.654867256637168,
      "grad_norm": 10.305895805358887,
      "learning_rate": 6.229910714285715e-07,
      "loss": 2.4263,
      "step": 1690
    },
    {
      "epoch": 29.831858407079647,
      "grad_norm": 3.3188140392303467,
      "learning_rate": 6.207589285714286e-07,
      "loss": 2.4903,
      "step": 1700
    },
    {
      "epoch": 30.0,
      "grad_norm": 3.9497897624969482,
      "learning_rate": 6.185267857142858e-07,
      "loss": 2.3396,
      "step": 1710
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.6515772342681885,
      "eval_runtime": 31.6119,
      "eval_samples_per_second": 3.195,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.5982227864170104,
      "step": 1710
    },
    {
      "epoch": 30.17699115044248,
      "grad_norm": 4.559182167053223,
      "learning_rate": 6.162946428571428e-07,
      "loss": 2.4199,
      "step": 1720
    },
    {
      "epoch": 30.353982300884955,
      "grad_norm": 10.592447280883789,
      "learning_rate": 6.140624999999999e-07,
      "loss": 2.4533,
      "step": 1730
    },
    {
      "epoch": 30.530973451327434,
      "grad_norm": 4.929714202880859,
      "learning_rate": 6.118303571428571e-07,
      "loss": 2.4316,
      "step": 1740
    },
    {
      "epoch": 30.707964601769913,
      "grad_norm": 12.242303848266602,
      "learning_rate": 6.095982142857142e-07,
      "loss": 2.4753,
      "step": 1750
    },
    {
      "epoch": 30.884955752212388,
      "grad_norm": 4.006100177764893,
      "learning_rate": 6.073660714285714e-07,
      "loss": 2.468,
      "step": 1760
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.6453789472579956,
      "eval_runtime": 32.7235,
      "eval_samples_per_second": 3.086,
      "eval_steps_per_second": 0.214,
      "eval_wer": 0.5950491907331006,
      "step": 1767
    },
    {
      "epoch": 31.053097345132745,
      "grad_norm": 5.1857099533081055,
      "learning_rate": 6.051339285714285e-07,
      "loss": 2.3812,
      "step": 1770
    },
    {
      "epoch": 31.23008849557522,
      "grad_norm": 4.096585750579834,
      "learning_rate": 6.029017857142857e-07,
      "loss": 2.5023,
      "step": 1780
    },
    {
      "epoch": 31.4070796460177,
      "grad_norm": 4.689417839050293,
      "learning_rate": 6.006696428571428e-07,
      "loss": 2.4244,
      "step": 1790
    },
    {
      "epoch": 31.58407079646018,
      "grad_norm": 7.986876964569092,
      "learning_rate": 5.984374999999999e-07,
      "loss": 2.4755,
      "step": 1800
    },
    {
      "epoch": 31.761061946902654,
      "grad_norm": 4.296658039093018,
      "learning_rate": 5.962053571428571e-07,
      "loss": 2.4772,
      "step": 1810
    },
    {
      "epoch": 31.938053097345133,
      "grad_norm": 5.887446880340576,
      "learning_rate": 5.939732142857142e-07,
      "loss": 2.4219,
      "step": 1820
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.6470155715942383,
      "eval_runtime": 31.8241,
      "eval_samples_per_second": 3.174,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.5936210726753411,
      "step": 1824
    },
    {
      "epoch": 32.10619469026549,
      "grad_norm": 4.330535888671875,
      "learning_rate": 5.917410714285715e-07,
      "loss": 2.3366,
      "step": 1830
    },
    {
      "epoch": 32.283185840707965,
      "grad_norm": 8.435574531555176,
      "learning_rate": 5.895089285714286e-07,
      "loss": 2.4485,
      "step": 1840
    },
    {
      "epoch": 32.46017699115044,
      "grad_norm": 4.054354190826416,
      "learning_rate": 5.872767857142858e-07,
      "loss": 2.4614,
      "step": 1850
    },
    {
      "epoch": 32.63716814159292,
      "grad_norm": 14.170822143554688,
      "learning_rate": 5.850446428571429e-07,
      "loss": 2.494,
      "step": 1860
    },
    {
      "epoch": 32.8141592920354,
      "grad_norm": 5.468540668487549,
      "learning_rate": 5.828125e-07,
      "loss": 2.449,
      "step": 1870
    },
    {
      "epoch": 32.991150442477874,
      "grad_norm": 6.544415473937988,
      "learning_rate": 5.805803571428572e-07,
      "loss": 2.4421,
      "step": 1880
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.6469194889068604,
      "eval_runtime": 31.2989,
      "eval_samples_per_second": 3.227,
      "eval_steps_per_second": 0.224,
      "eval_wer": 0.5931450333227547,
      "step": 1881
    },
    {
      "epoch": 33.15929203539823,
      "grad_norm": 7.222659587860107,
      "learning_rate": 5.783482142857142e-07,
      "loss": 2.3276,
      "step": 1890
    },
    {
      "epoch": 33.336283185840706,
      "grad_norm": 4.775232315063477,
      "learning_rate": 5.761160714285714e-07,
      "loss": 2.4658,
      "step": 1900
    },
    {
      "epoch": 33.51327433628319,
      "grad_norm": 4.86133337020874,
      "learning_rate": 5.738839285714285e-07,
      "loss": 2.468,
      "step": 1910
    },
    {
      "epoch": 33.690265486725664,
      "grad_norm": 5.481078147888184,
      "learning_rate": 5.716517857142857e-07,
      "loss": 2.4945,
      "step": 1920
    },
    {
      "epoch": 33.86725663716814,
      "grad_norm": 3.3559727668762207,
      "learning_rate": 5.694196428571428e-07,
      "loss": 2.4418,
      "step": 1930
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.6386547088623047,
      "eval_runtime": 32.6428,
      "eval_samples_per_second": 3.094,
      "eval_steps_per_second": 0.214,
      "eval_wer": 0.5928276737543637,
      "step": 1938
    },
    {
      "epoch": 34.0353982300885,
      "grad_norm": 5.564451694488525,
      "learning_rate": 5.671874999999999e-07,
      "loss": 2.3529,
      "step": 1940
    },
    {
      "epoch": 34.21238938053097,
      "grad_norm": 3.8840739727020264,
      "learning_rate": 5.649553571428571e-07,
      "loss": 2.4056,
      "step": 1950
    },
    {
      "epoch": 34.389380530973455,
      "grad_norm": 16.50359535217285,
      "learning_rate": 5.627232142857142e-07,
      "loss": 2.4191,
      "step": 1960
    },
    {
      "epoch": 34.56637168141593,
      "grad_norm": 3.7693734169006348,
      "learning_rate": 5.604910714285714e-07,
      "loss": 2.4127,
      "step": 1970
    },
    {
      "epoch": 34.743362831858406,
      "grad_norm": 4.803380966186523,
      "learning_rate": 5.582589285714285e-07,
      "loss": 2.4544,
      "step": 1980
    },
    {
      "epoch": 34.92035398230089,
      "grad_norm": 4.718769550323486,
      "learning_rate": 5.560267857142858e-07,
      "loss": 2.5588,
      "step": 1990
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.6340749263763428,
      "eval_runtime": 31.7408,
      "eval_samples_per_second": 3.182,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.5944144715963187,
      "step": 1995
    },
    {
      "epoch": 35.08849557522124,
      "grad_norm": 3.9786109924316406,
      "learning_rate": 5.537946428571429e-07,
      "loss": 2.3393,
      "step": 2000
    },
    {
      "epoch": 35.26548672566372,
      "grad_norm": 4.9766011238098145,
      "learning_rate": 5.515625e-07,
      "loss": 2.487,
      "step": 2010
    },
    {
      "epoch": 35.442477876106196,
      "grad_norm": 3.8675642013549805,
      "learning_rate": 5.493303571428572e-07,
      "loss": 2.4946,
      "step": 2020
    },
    {
      "epoch": 35.61946902654867,
      "grad_norm": 4.402736186981201,
      "learning_rate": 5.470982142857143e-07,
      "loss": 2.4565,
      "step": 2030
    },
    {
      "epoch": 35.796460176991154,
      "grad_norm": 8.196366310119629,
      "learning_rate": 5.448660714285715e-07,
      "loss": 2.5119,
      "step": 2040
    },
    {
      "epoch": 35.97345132743363,
      "grad_norm": 4.430672645568848,
      "learning_rate": 5.426339285714286e-07,
      "loss": 2.4222,
      "step": 2050
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.638267159461975,
      "eval_runtime": 32.0315,
      "eval_samples_per_second": 3.153,
      "eval_steps_per_second": 0.219,
      "eval_wer": 0.5910821961282132,
      "step": 2052
    },
    {
      "epoch": 36.14159292035398,
      "grad_norm": 4.33438777923584,
      "learning_rate": 5.404017857142857e-07,
      "loss": 2.3378,
      "step": 2060
    },
    {
      "epoch": 36.31858407079646,
      "grad_norm": 5.749685764312744,
      "learning_rate": 5.381696428571428e-07,
      "loss": 2.4397,
      "step": 2070
    },
    {
      "epoch": 36.49557522123894,
      "grad_norm": 4.097780227661133,
      "learning_rate": 5.359374999999999e-07,
      "loss": 2.4399,
      "step": 2080
    },
    {
      "epoch": 36.67256637168141,
      "grad_norm": 6.309570789337158,
      "learning_rate": 5.337053571428571e-07,
      "loss": 2.4665,
      "step": 2090
    },
    {
      "epoch": 36.849557522123895,
      "grad_norm": 4.028100490570068,
      "learning_rate": 5.314732142857142e-07,
      "loss": 2.4911,
      "step": 2100
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.6333611011505127,
      "eval_runtime": 31.8902,
      "eval_samples_per_second": 3.167,
      "eval_steps_per_second": 0.22,
      "eval_wer": 0.5921929546175817,
      "step": 2109
    },
    {
      "epoch": 37.017699115044245,
      "grad_norm": 15.638299942016602,
      "learning_rate": 5.292410714285714e-07,
      "loss": 2.3823,
      "step": 2110
    },
    {
      "epoch": 37.19469026548673,
      "grad_norm": 6.336103439331055,
      "learning_rate": 5.270089285714285e-07,
      "loss": 2.4485,
      "step": 2120
    },
    {
      "epoch": 37.3716814159292,
      "grad_norm": 4.415156841278076,
      "learning_rate": 5.247767857142857e-07,
      "loss": 2.4612,
      "step": 2130
    },
    {
      "epoch": 37.54867256637168,
      "grad_norm": 3.7268078327178955,
      "learning_rate": 5.225446428571428e-07,
      "loss": 2.5209,
      "step": 2140
    },
    {
      "epoch": 37.72566371681416,
      "grad_norm": 4.652563571929932,
      "learning_rate": 5.203124999999999e-07,
      "loss": 2.4852,
      "step": 2150
    },
    {
      "epoch": 37.902654867256636,
      "grad_norm": 2.940784215927124,
      "learning_rate": 5.180803571428572e-07,
      "loss": 2.4341,
      "step": 2160
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.6302375793457031,
      "eval_runtime": 32.348,
      "eval_samples_per_second": 3.122,
      "eval_steps_per_second": 0.216,
      "eval_wer": 0.5896540780704538,
      "step": 2166
    },
    {
      "epoch": 38.07079646017699,
      "grad_norm": 4.795915603637695,
      "learning_rate": 5.158482142857143e-07,
      "loss": 2.2889,
      "step": 2170
    },
    {
      "epoch": 38.24778761061947,
      "grad_norm": 3.824899435043335,
      "learning_rate": 5.136160714285715e-07,
      "loss": 2.4571,
      "step": 2180
    },
    {
      "epoch": 38.424778761061944,
      "grad_norm": 5.584535121917725,
      "learning_rate": 5.113839285714286e-07,
      "loss": 2.4271,
      "step": 2190
    },
    {
      "epoch": 38.60176991150443,
      "grad_norm": 3.714970111846924,
      "learning_rate": 5.091517857142858e-07,
      "loss": 2.4344,
      "step": 2200
    },
    {
      "epoch": 38.7787610619469,
      "grad_norm": 5.829850196838379,
      "learning_rate": 5.069196428571429e-07,
      "loss": 2.4213,
      "step": 2210
    },
    {
      "epoch": 38.95575221238938,
      "grad_norm": 5.292644500732422,
      "learning_rate": 5.046875e-07,
      "loss": 2.4789,
      "step": 2220
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.6282219886779785,
      "eval_runtime": 31.703,
      "eval_samples_per_second": 3.186,
      "eval_steps_per_second": 0.221,
      "eval_wer": 0.5888606791494764,
      "step": 2223
    },
    {
      "epoch": 39.123893805309734,
      "grad_norm": 5.923223495483398,
      "learning_rate": 5.024553571428571e-07,
      "loss": 2.2753,
      "step": 2230
    },
    {
      "epoch": 39.30088495575221,
      "grad_norm": 7.688230991363525,
      "learning_rate": 5.002232142857142e-07,
      "loss": 2.483,
      "step": 2240
    },
    {
      "epoch": 39.47787610619469,
      "grad_norm": 5.598474502563477,
      "learning_rate": 4.979910714285714e-07,
      "loss": 2.4744,
      "step": 2250
    },
    {
      "epoch": 39.65486725663717,
      "grad_norm": 5.7022013664245605,
      "learning_rate": 4.957589285714285e-07,
      "loss": 2.4335,
      "step": 2260
    },
    {
      "epoch": 39.83185840707964,
      "grad_norm": 5.0888142585754395,
      "learning_rate": 4.935267857142857e-07,
      "loss": 2.462,
      "step": 2270
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.839365243911743,
      "learning_rate": 4.912946428571428e-07,
      "loss": 2.3259,
      "step": 2280
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.6227099895477295,
      "eval_runtime": 31.5706,
      "eval_samples_per_second": 3.199,
      "eval_steps_per_second": 0.222,
      "eval_wer": 0.5898127578546494,
      "step": 2280
    }
  ],
  "logging_steps": 10,
  "max_steps": 4480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 80,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.808759369728e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
